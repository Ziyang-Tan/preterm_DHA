{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "import os\n",
    "import anndata\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from fcsy import DataFrame\n",
    "import matplotlib\n",
    "from glob import glob\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "matplotlib.rcParams['ps.fonttype']=42\n",
    "\n",
    "# scanpy settings\n",
    "sc.settings.verbosity = 0  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.settings.set_figure_params(dpi=150, frameon=False, figsize=(4, 4)) \n",
    "sc._settings.ScanpyConfig.n_jobs=4\n",
    "\n",
    "# readin the information table\n",
    "sampleInfo = pd.read_excel(os.path.join('/Users/tan/preterm_DHA/data', \n",
    "                                        '210825_database_for_petter_sent_210826.xlsx'), \n",
    "                         dtype={'Inf_ID':str})\n",
    "selectInfo = sampleInfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tan/anaconda3/envs/PAGA-2/lib/python3.7/site-packages/anndata/_core/anndata.py:120: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "dataDir = '/Users/tan/cytof_data/*/renamed'\n",
    "labelDir = '/Users/tan/cytof_data/*/(classifiedV3)'\n",
    "\n",
    "drop_dic = {'B-cells': ['CD33', 'CD3', 'TCRgd', 'Siglec-8', 'CD14', 'CD141', 'CD4', 'pan-KIR'],\n",
    "            'CD4 T': ['IgD', 'CD1c', 'TCRgd', 'Siglec-8', 'CD20', 'CD14'],\n",
    "            'CD8 T': ['IgD', 'CD11c', 'CD1c', 'TCRgd', 'Siglec-8', 'CD20', 'CD14'],\n",
    "            'Eosinophils': ['IgD', 'CD57', 'CD25', 'TCRgd', 'CD14', 'pan-KIR'],\n",
    "            'Monocytes': ['CD57', 'IgD', 'CD25', 'CD20', 'TCRgd', 'CD22', 'CD127', 'pan-KIR'], \n",
    "            'Neutrophils': ['IgD', 'HLA-DR', 'CD57', 'CD25', 'CD22', 'TCRgd', 'CD123', 'CD161', 'pan-KIR'],\n",
    "            'NK-cells': [],\n",
    "            'Plasmablasts': [],\n",
    "            #'Basophils': [],\n",
    "            'Tregs':[],\n",
    "            'pDC': []\n",
    "           }\n",
    "\n",
    "# readin and merge the file according to \"selectInfo\" as an anndata object\n",
    "\n",
    "all_data_path = 'adata/all_data_preterm_DHA.h5ad'\n",
    "if not os.path.exists(all_data_path):\n",
    "    print('adata not found, load and preprocess raw data...')\n",
    "    all_data_list = []\n",
    "    all_label_list = []\n",
    "    for i in range(len(selectInfo)):\n",
    "        label_path = glob(labelDir + '/*/' + str(selectInfo['ID_unique'].iloc[i]) + '.csv')[0]\n",
    "        data_path = glob(dataDir + '/*/' + str(selectInfo['ID_unique'].iloc[i]) + '.fcs')[0]\n",
    "        labelTmp = pd.read_csv(label_path)\n",
    "        labelTmp['ID_unique'] = np.repeat(selectInfo['ID_unique'].iloc[i], len(labelTmp.index))\n",
    "        labelTmp['timepoint'] = np.repeat(selectInfo['Timepoint_string'].iloc[i], len(labelTmp.index))\n",
    "        labelTmp['Inf_ID'] = np.repeat(str(selectInfo['Inf_ID'].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['PN_days'] = np.repeat(str(selectInfo['PN_days_sample'].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['group'] = np.repeat(str(selectInfo['randtrt'].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['timepoint_group'] = np.repeat(selectInfo['Timepoint_string'].iloc[i] + \n",
    "                                                '_' + \n",
    "                                                str(selectInfo['randtrt'].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['batch'] = np.repeat(data_path.split('/')[-4], len(labelTmp.index)) #EXP-XX-XXXXXX\n",
    "        dataTmp = DataFrame.from_fcs(data_path, channel_type='long')\n",
    "        # filter the cells without a level1 tag\n",
    "        dataTmp = dataTmp[labelTmp['level1']!=' ']\n",
    "        labelTmp = labelTmp[labelTmp['level1']!=' ']\n",
    "        # remove EQBeads and DNA channel # also remove the negative channels\n",
    "        dataTmp.drop(columns=['Time', 'Event_length', 'Center', 'Offset', 'Width', 'Residual',\n",
    "                               '102Pd', '104Pd', '105Pd', '106Pd', '108Pd', \n",
    "                               '116Cd', '131Xe', '133Cs', '191Ir', '193Ir'], inplace=True)\n",
    "        dataTmp = np.arcsinh(dataTmp/5)\n",
    "        all_data_list.append(dataTmp)\n",
    "        all_label_list.append(labelTmp)\n",
    "    \n",
    "    all_data = pd.concat(all_data_list, ignore_index=True)\n",
    "    all_label = pd.concat(all_label_list, ignore_index=True)\n",
    "    adata = anndata.AnnData(all_data)\n",
    "    adata.obs = all_label\n",
    "    adata.raw = adata # store the raw (with asinh only)\n",
    "    sc.pp.combat(adata, key = 'batch', covariates = ['timepoint', 'group'])\n",
    "    sc.pp.scale(adata)\n",
    "    os.makedirs('adata/', exist_ok=True)\n",
    "    adata.write(filename=all_data_path, compression = 'gzip')\n",
    "    adata=None\n",
    "    print('finished!')\n",
    "print('loading...')\n",
    "adata_all = sc.read_h5ad(filename = all_data_path)\n",
    "print('finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-20e8d3ae0db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msub_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Tregs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0msample_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madata_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madata_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CD39 Memory Tregs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Memory Tregs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Naive Tregs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ID_unique'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mnsample\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdroplevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0madata_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madata_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# usually when no file has more cells than nsample and thus no subsampling at all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_index' is not defined"
     ]
    }
   ],
   "source": [
    "nsample = 1000\n",
    "#for sub_name in drop_dic:\n",
    "#for sub_name in ['Neutrophils', 'NK-cells', 'Plasmablasts', 'Basophils', 'Tregs', 'pDC']:\n",
    "for sub_name in ['Basophils']:\n",
    "    # subsampling and drop negative columns\n",
    "    try:\n",
    "        if sub_name in adata_all.obs['level1'].unique().tolist():\n",
    "            sample_index = adata_all.obs[adata_all.obs['level1']==sub_name].groupby('ID_unique').apply(lambda x: x.sample(n=nsample, random_state=0) if x.shape[0]>=nsample else x).index.droplevel(level=0)\n",
    "        elif sub_name in adata_all.obs['level2'].unique().tolist():\n",
    "            sample_index = adata_all.obs[adata_all.obs['level2']==sub_name].groupby('ID_unique').apply(lambda x: x.sample(n=nsample, random_state=0) if x.shape[0]>=nsample else x).index.droplevel(level=0)\n",
    "        elif sub_name == 'Tregs':\n",
    "            sample_index = adata_all.obs[adata_all.obs['level3'].isin(['CD39 Memory Tregs', 'Memory Tregs', 'Naive Tregs'])].groupby('ID_unique').apply(lambda x: x.sample(n=nsample, random_state=0) if x.shape[0]>=nsample else x).index.droplevel(level=0)        \n",
    "        adata_sample = adata_all[sample_index]\n",
    "    except ValueError as e: \n",
    "        # usually when no file has more cells than nsample and thus no subsampling at all.\n",
    "        # so the results after apply will not be a multiplex index and the droplevel func will fail.\n",
    "        print(e)\n",
    "        if sub_name in adata_all.obs['level1'].unique().tolist():\n",
    "            adata_sample = adata_all[adata_all.obs['level1']==sub_name]\n",
    "        elif sub_name in adata_all.obs['level2'].unique().tolist():\n",
    "            adata_sample = adata_all[adata_all.obs['level2']==sub_name]\n",
    "        elif sub_name == 'Tregs':\n",
    "            adata_sample = adata_all[adata_all.obs['level3'].isin(['CD39 Memory Tregs', 'Memory Tregs', 'Naive Tregs'])]\n",
    "\n",
    "    drop_indicator = np.in1d(adata_sample.var_names, drop_dic[sub_name])\n",
    "    adata = adata_sample[:,~drop_indicator]\n",
    "\n",
    "    # save figures to a sub dir\n",
    "    figpath='./figures/' + sub_name + '/'\n",
    "    os.makedirs(figpath, exist_ok=True)\n",
    "    sc.settings.figdir=figpath\n",
    "\n",
    "    #n_comps = min([adata.n_obs, adata.n_vars, 21])-1\n",
    "    #sc.tl.pca(adata, svd_solver='arpack', n_comps=n_comps)\n",
    "    sc.pp.neighbors(adata, n_neighbors=10)\n",
    "\n",
    "    # paga process\n",
    "    sc.tl.leiden(adata, resolution=0.3) \n",
    "\n",
    "    sc.tl.paga(adata, groups='leiden')\n",
    "    sc.pl.paga(adata, color=['leiden'], threshold=0.1, show=False, \n",
    "               save='_' + sub_name + '.pdf')\n",
    "\n",
    "    sc.tl.draw_graph(adata, init_pos='paga')\n",
    "\n",
    "    sc.pl.draw_graph(adata, color=['timepoint', 'group', 'leiden', 'batch'], show=False,\n",
    "                     save='_' + sub_name + '.pdf')\n",
    "\n",
    "    sc.pl.draw_graph(adata, color=adata.var.index.values, show=False, use_raw=True, \n",
    "                     save='_' + sub_name + '_markers.pdf')\n",
    "\n",
    "    sc.tl.embedding_density(adata, basis='draw_graph_fa', groupby='group')\n",
    "    sc.pl.embedding_density(adata, basis='draw_graph_fa', key='draw_graph_fa_density_group', \n",
    "                            group=['1', '2'],\n",
    "                            save='_' + sub_name + '_group_density.pdf')\n",
    "    sc.tl.embedding_density(adata, basis='draw_graph_fa', groupby='timepoint_group')\n",
    "    sc.pl.embedding_density(adata, basis='draw_graph_fa', key='draw_graph_fa_density_timepoint_group', \n",
    "                            group=['Day 1_1', 'Day 3_1', 'Day 7_1', 'Day 14_1', 'Day 28_1', 'PMA 40 weeks_1'],\n",
    "                            save='_' + sub_name + '_timepoint_group1_density.pdf')\n",
    "    sc.pl.embedding_density(adata, basis='draw_graph_fa', key='draw_graph_fa_density_timepoint_group', \n",
    "                            group=['Day 1_2', 'Day 3_2', 'Day 7_2', 'Day 14_2', 'Day 28_2', 'PMA 40 weeks_2'],\n",
    "                            save='_' + sub_name + '_timepoint_group2_density.pdf')\n",
    "\n",
    "\n",
    "    os.makedirs('PAGA_result_data/', exist_ok=True)\n",
    "    adata.X = adata.raw.X[:,~drop_indicator]\n",
    "    adata.write(filename='PAGA_result_data/all_' + sub_name + '_sample1000_raw.h5ad', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
